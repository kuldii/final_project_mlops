{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Information\n",
    "\n",
    "* Сандикха Рахарди РИМ-130908\n",
    "* Мухин Виктор Александрович РИМ-130908"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Dataset\n",
    "\n",
    "We are using this dataset from kaggle :\n",
    "[Download Dataset](https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis)\n",
    "\n",
    "### Overview\n",
    "This is an entity-level sentiment analysis dataset of twitter. Given a message and an entity, the task is to judge the sentiment of the message about the entity. There are three classes in this dataset: Positive, Negative and Neutral. We regard messages that are not relevant to the entity (i.e. Irrelevant) as Neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import torch\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('data/twitter_training.csv.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74681</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74682 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       entity sentiment  \\\n",
       "0      2401  Borderlands  Positive   \n",
       "1      2401  Borderlands  Positive   \n",
       "2      2401  Borderlands  Positive   \n",
       "3      2401  Borderlands  Positive   \n",
       "4      2401  Borderlands  Positive   \n",
       "...     ...          ...       ...   \n",
       "74677  9200       Nvidia  Positive   \n",
       "74678  9200       Nvidia  Positive   \n",
       "74679  9200       Nvidia  Positive   \n",
       "74680  9200       Nvidia  Positive   \n",
       "74681  9200       Nvidia  Positive   \n",
       "\n",
       "                                                 content  \n",
       "0      im getting on borderlands and i will murder yo...  \n",
       "1      I am coming to the borders and I will kill you...  \n",
       "2      im getting on borderlands and i will kill you ...  \n",
       "3      im coming on borderlands and i will murder you...  \n",
       "4      im getting on borderlands 2 and i will murder ...  \n",
       "...                                                  ...  \n",
       "74677  Just realized that the Windows partition of my...  \n",
       "74678  Just realized that my Mac window partition is ...  \n",
       "74679  Just realized the windows partition of my Mac ...  \n",
       "74680  Just realized between the windows partition of...  \n",
       "74681  Just like the windows partition of my Mac is l...  \n",
       "\n",
       "[74682 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_training_df = pd.read_csv('data/twitter_training.csv', names=['id', 'entity', 'sentiment', 'content'])\n",
    "twitter_training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3364</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>I mentioned on Facebook that I was struggling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>BBC News - Amazon boss Jeff Bezos rejects clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8312</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@Microsoft Why do I pay for WORD when it funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4371</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Negative</td>\n",
       "      <td>CSGO matchmaking is so full of closet hacking,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4433</td>\n",
       "      <td>Google</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Now the President is slapping Americans in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4891</td>\n",
       "      <td>GrandTheftAuto(GTA)</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>⭐️ Toronto is the arts and culture capital of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>4359</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2652</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Today sucked so it’s time to drink wine n play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>8069</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Bought a fraction of Microsoft today. Small wins.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>6960</td>\n",
       "      <td>johnson&amp;johnson</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Johnson &amp; Johnson to stop selling talc baby po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id               entity   sentiment  \\\n",
       "0    3364             Facebook  Irrelevant   \n",
       "1     352               Amazon     Neutral   \n",
       "2    8312            Microsoft    Negative   \n",
       "3    4371                CS-GO    Negative   \n",
       "4    4433               Google     Neutral   \n",
       "..    ...                  ...         ...   \n",
       "995  4891  GrandTheftAuto(GTA)  Irrelevant   \n",
       "996  4359                CS-GO  Irrelevant   \n",
       "997  2652          Borderlands    Positive   \n",
       "998  8069            Microsoft    Positive   \n",
       "999  6960      johnson&johnson     Neutral   \n",
       "\n",
       "                                               content  \n",
       "0    I mentioned on Facebook that I was struggling ...  \n",
       "1    BBC News - Amazon boss Jeff Bezos rejects clai...  \n",
       "2    @Microsoft Why do I pay for WORD when it funct...  \n",
       "3    CSGO matchmaking is so full of closet hacking,...  \n",
       "4    Now the President is slapping Americans in the...  \n",
       "..                                                 ...  \n",
       "995  ⭐️ Toronto is the arts and culture capital of ...  \n",
       "996  tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...  \n",
       "997  Today sucked so it’s time to drink wine n play...  \n",
       "998  Bought a fraction of Microsoft today. Small wins.  \n",
       "999  Johnson & Johnson to stop selling talc baby po...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_validation_df = pd.read_csv('data/twitter_validation.csv', names=['id', 'entity', 'sentiment', 'content'])\n",
    "twitter_validation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Data Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of Dataset: 74682\n",
      "\n",
      "Positive Records: 20655\n",
      "Negative Records: 22358\n",
      "Neutral Records: 18108\n",
      "Irrelevant Records: 12875\n",
      "==========================\n",
      "Total Records: 73996\n"
     ]
    }
   ],
   "source": [
    "total_data = len(twitter_training_df)\n",
    "twitter_training_df.dropna(axis=0, inplace=True)\n",
    "positive_records = len(twitter_training_df[twitter_training_df['sentiment'] == 'Positive'])\n",
    "negative_records = len(twitter_training_df[twitter_training_df['sentiment'] == 'Negative'])\n",
    "neutral_records = len(twitter_training_df[twitter_training_df['sentiment'] == 'Neutral'])\n",
    "irrelevant_records = len(twitter_training_df[twitter_training_df['sentiment'] == 'Irrelevant'])\n",
    "\n",
    "print(f\"Total of Dataset: {total_data}\\n\")\n",
    "print(f\"Positive Records: {positive_records}\")\n",
    "print(f\"Negative Records: {negative_records}\")\n",
    "print(f\"Neutral Records: {neutral_records}\")\n",
    "print(f\"Irrelevant Records: {irrelevant_records}\")\n",
    "print(\"==========================\")\n",
    "print(f\"Total Records: {positive_records + negative_records + neutral_records + irrelevant_records}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of Dataset: 1000\n",
      "\n",
      "Positive Records: 277\n",
      "Negative Records: 266\n",
      "Neutral Records: 285\n",
      "Irrelevant Records: 172\n",
      "==========================\n",
      "Total Records: 1000\n"
     ]
    }
   ],
   "source": [
    "total_data = len(twitter_validation_df)\n",
    "twitter_validation_df.dropna(axis=0, inplace=True)\n",
    "positive_records = len(twitter_validation_df[twitter_validation_df['sentiment'] == 'Positive'])\n",
    "negative_records = len(twitter_validation_df[twitter_validation_df['sentiment'] == 'Negative'])\n",
    "neutral_records = len(twitter_validation_df[twitter_validation_df['sentiment'] == 'Neutral'])\n",
    "irrelevant_records = len(twitter_validation_df[twitter_validation_df['sentiment'] == 'Irrelevant'])\n",
    "\n",
    "print(f\"Total of Dataset: {total_data}\\n\")\n",
    "print(f\"Positive Records: {positive_records}\")\n",
    "print(f\"Negative Records: {negative_records}\")\n",
    "print(f\"Neutral Records: {neutral_records}\")\n",
    "print(f\"Irrelevant Records: {irrelevant_records}\")\n",
    "print(\"==========================\")\n",
    "print(f\"Total Records: {positive_records + negative_records + neutral_records + irrelevant_records}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        tokens = word_tokenize(text)\n",
    "        filtered_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "        return ' '.join(filtered_tokens)\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74991</th>\n",
       "      <td>4891</td>\n",
       "      <td>GrandTheftAuto(GTA)</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>⭐️ Toronto is the arts and culture capital of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74992</th>\n",
       "      <td>4359</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74993</th>\n",
       "      <td>2652</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Today sucked so it’s time to drink wine n play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74994</th>\n",
       "      <td>8069</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Bought a fraction of Microsoft today. Small wins.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>6960</td>\n",
       "      <td>johnson&amp;johnson</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Johnson &amp; Johnson to stop selling talc baby po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74996 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id               entity   sentiment  \\\n",
       "0      2401          Borderlands    Positive   \n",
       "1      2401          Borderlands    Positive   \n",
       "2      2401          Borderlands    Positive   \n",
       "3      2401          Borderlands    Positive   \n",
       "4      2401          Borderlands    Positive   \n",
       "...     ...                  ...         ...   \n",
       "74991  4891  GrandTheftAuto(GTA)  Irrelevant   \n",
       "74992  4359                CS-GO  Irrelevant   \n",
       "74993  2652          Borderlands    Positive   \n",
       "74994  8069            Microsoft    Positive   \n",
       "74995  6960      johnson&johnson     Neutral   \n",
       "\n",
       "                                                 content  \n",
       "0      im getting on borderlands and i will murder yo...  \n",
       "1      I am coming to the borders and I will kill you...  \n",
       "2      im getting on borderlands and i will kill you ...  \n",
       "3      im coming on borderlands and i will murder you...  \n",
       "4      im getting on borderlands 2 and i will murder ...  \n",
       "...                                                  ...  \n",
       "74991  ⭐️ Toronto is the arts and culture capital of ...  \n",
       "74992  tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...  \n",
       "74993  Today sucked so it’s time to drink wine n play...  \n",
       "74994  Bought a fraction of Microsoft today. Small wins.  \n",
       "74995  Johnson & Johnson to stop selling talc baby po...  \n",
       "\n",
       "[74996 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([twitter_training_df, twitter_validation_df], axis=0).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words in positive comments:\n",
      "[('game', 3159), ('love', 1833), ('im', 1796), ('good', 1638), ('like', 1394), ('really', 1305), ('new', 1218), ('time', 1157), ('play', 1139), ('best', 1136)]\n",
      "\n",
      "Most common words in negative comments:\n",
      "[('game', 4567), ('get', 1849), ('like', 1655), ('shit', 1544), ('im', 1446), ('fix', 1341), ('fuck', 1305), ('play', 1253), ('cant', 1247), ('dont', 1146)]\n",
      "\n",
      "Most common words in neutral comments:\n",
      "[('johnson', 1846), ('game', 1643), ('amazon', 1176), ('_', 1080), ('get', 1031), ('like', 960), ('u', 935), ('im', 914), ('one', 894), ('google', 869)]\n",
      "\n",
      "Most common words in irrelevant comments:\n",
      "[('player', 1145), ('game', 1128), ('like', 1032), ('see', 957), ('im', 872), ('people', 781), ('ban', 763), ('one', 720), ('love', 713), ('good', 674)]\n"
     ]
    }
   ],
   "source": [
    "df['cleaned'] = df['content'].apply(preprocess_text)\n",
    "\n",
    "positive_texts = ' '.join(df[df['sentiment'] == 'Positive']['cleaned']).split()\n",
    "negative_texts = ' '.join(df[df['sentiment'] == 'Negative']['cleaned']).split()\n",
    "neutral_texts = ' '.join(df[df['sentiment'] == 'Neutral']['cleaned']).split()\n",
    "irrelevant_texts = ' '.join(df[df['sentiment'] == 'Irrelevant']['cleaned']).split()\n",
    "\n",
    "positive_counter = Counter(positive_texts)\n",
    "negative_counter = Counter(negative_texts)\n",
    "neutral_counter = Counter(neutral_texts)\n",
    "irrelevant_counter = Counter(irrelevant_texts)\n",
    "\n",
    "print(\"Most common words in positive comments:\")\n",
    "print(positive_counter.most_common(10))\n",
    "\n",
    "print(\"\\nMost common words in negative comments:\")\n",
    "print(negative_counter.most_common(10))\n",
    "\n",
    "print(\"\\nMost common words in neutral comments:\")\n",
    "print(neutral_counter.most_common(10))\n",
    "\n",
    "print(\"\\nMost common words in irrelevant comments:\")\n",
    "print(irrelevant_counter.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['cleaned']\n",
    "y = df['sentiment']\n",
    "\n",
    "validation_size = 1000\n",
    "X_train = X[:-validation_size]\n",
    "y_train = y[:-validation_size]\n",
    "X_val = X[-validation_size:]\n",
    "y_val = y[-validation_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save X_train and y_train to CSV files\n",
    "X_train.to_csv('data/X_train.csv', index=False)\n",
    "y_train.to_csv('data/y_train.csv', index=False)\n",
    "\n",
    "# Save X_val and y_val to CSV files\n",
    "X_val.to_csv('data/X_val.csv', index=False)\n",
    "y_val.to_csv('data/y_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multinomial Naive Bayes:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.98      0.62      0.76       172\n",
      "    Negative       0.70      0.94      0.80       266\n",
      "     Neutral       0.95      0.70      0.81       285\n",
      "  Irrelevant       0.78      0.91      0.84       277\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.85      0.79      0.80      1000\n",
      "weighted avg       0.84      0.81      0.81      1000\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.99      0.97      0.98       172\n",
      "    Negative       0.97      0.97      0.97       266\n",
      "     Neutral       0.98      0.98      0.98       285\n",
      "  Irrelevant       0.97      0.98      0.97       277\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.98      0.97      0.97      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation every models\n",
    "for model_name, model in models.items():\n",
    "    pipeline = make_pipeline(TfidfVectorizer(), model)\n",
    "    \n",
    "    # Training Model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Validation Model\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "    \n",
    "    # Evaluate Model\n",
    "    print(f\"\\n{model_name}:\\n\")\n",
    "    print(classification_report(y_val, y_pred, target_names=['Positive', 'Negative', 'Neutral', 'Irrelevant']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
